{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJ_9TWS4D2zs"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/160HDHTr2dowC8ISeVBH8aHndbTDQNpws)\n",
    "\n",
    "Sources\n",
    "- [article](https://www.projectpro.io/article/python-chatbot-project-learn-to-build-a-chatbot-from-scratch/429#mcetoc_1fofi4362b)\n",
    "- [github](https://github.com/dianastubbegit/ChatBot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNSjM13kD2zw"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cq1VypA0Mvc6",
    "outputId": "13140598-57be-433f-ea71-a3cb1be88708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#1 Mounting the Google Drive\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "data_root='/content/drive/My Drive/ChatBot' #Please upload the files in your drive and change the path to it accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGBB8SU2EdQo"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x9tmODfxE9Op",
    "outputId": "af2966e2-022a-40ad-c53f-541880b64a65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xkvi7jGbM8yE",
    "outputId": "4de5c777-32b3-4561-dcdb-f45c5751910d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 Importing Relevant Libraries\n",
    "\n",
    "import json\n",
    "import string\n",
    "import random \n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "le2pj3gpiqc8",
    "outputId": "88cf273b-749d-4539-8df1-905d860f93e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'tag': 'greeting',\n",
       "   'patterns': ['Hi',\n",
       "    'Hi there',\n",
       "    'How are you',\n",
       "    'Is anyone there?',\n",
       "    'Hey',\n",
       "    'Hello',\n",
       "    'Good day'],\n",
       "   'responses': ['Hi, how can I assist?',\n",
       "    'Hello, how can I help you today?',\n",
       "    'Hi, I am great, how can I help today?',\n",
       "    'Good to see you again!',\n",
       "    'Hi there, how can I help?'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'goodbye',\n",
       "   'patterns': ['Bye',\n",
       "    'See you later',\n",
       "    'Goodbye',\n",
       "    'Nice chatting with you, bye',\n",
       "    'Till next time'],\n",
       "   'responses': ['See you!',\n",
       "    'Have a nice day!',\n",
       "    'Thank you, see you again soon!',\n",
       "    'Bye! Come back again soon.',\n",
       "    'Goodbye'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'thanks',\n",
       "   'patterns': ['Thanks',\n",
       "    'Thank you',\n",
       "    \"That's helpful\",\n",
       "    'Awesome, thanks',\n",
       "    'Thanks for helping me'],\n",
       "   'responses': ['Happy to help!',\n",
       "    'Any time!',\n",
       "    'Glad I was able to help!',\n",
       "    'You are welcome!',\n",
       "    'My pleasure'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'noanswer',\n",
       "   'patterns': [],\n",
       "   'responses': [\"Sorry, can't understand you\",\n",
       "    'Please provide more information',\n",
       "    'Not sure I understand'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'options',\n",
       "   'patterns': ['How can you help me?',\n",
       "    'What type of help do you provide?',\n",
       "    'How can you be helpful?',\n",
       "    'What do you do?'],\n",
       "   'responses': ['I can guide you through: \\n-adverse management problems, \\n-order tracking, \\n-person to be contacted, \\n-department related queries, \\n-or even weather forecasts for countries in the main language for that country'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'order_tracking',\n",
       "   'patterns': ['What is happening with order 55555?',\n",
       "    'What is the status for order 55555?',\n",
       "    'Track order 55555',\n",
       "    'Where is my order 55555?'],\n",
       "   'responses': ['Delayed', 'Dispatched', 'Cancelled', 'On the Way!'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'order_components',\n",
       "   'patterns': ['order 55555 comprises of?',\n",
       "    'What is in order 55555?',\n",
       "    'List of components'],\n",
       "   'responses': ['The order comprises of a computer and a television',\n",
       "    'The order includes dog treats and a dog bed'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'missing_id',\n",
       "   'patterns': ['Where is the order?',\n",
       "    'Where is my order?',\n",
       "    'Locate the order',\n",
       "    'Delivery date of order'],\n",
       "   'responses': [\"Please enter with order's ID\",\n",
       "    'Which order are you referring to?'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'Location',\n",
       "   'patterns': ['Please find the location for order 55555',\n",
       "    'What is the location for order 55555?'],\n",
       "   'responses': ['It is in Germany',\n",
       "    'It is in France',\n",
       "    'It is in the United States',\n",
       "    'It has reached China'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'search_person_by_id',\n",
       "   'patterns': ['I want an appoitment with Dr. Jane Doe',\n",
       "    'Please set an appointment with Dr. James Jones'],\n",
       "   'responses': ['Fixing an appointment.', 'Setting up an appointment now.'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'appointment_status',\n",
       "   'patterns': ['Is my appointment fixed?', 'Do I have an appointment today?'],\n",
       "   'responses': ['Yes', 'All set!', 'No! Not Yet'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'check_leave',\n",
       "   'patterns': ['Is Dr. Jane Doe on leave?', 'Is Dr. James Jones on leave?'],\n",
       "   'responses': ['Not On Leave', 'Yes On Leave'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'forgot_password',\n",
       "   'patterns': ['I forgot my login password',\n",
       "    'what to do when someone forgets their password?',\n",
       "    'I forgot my work password',\n",
       "    'Forgot the virtual machine password'],\n",
       "   'responses': ['Please enter your email id and we will send a link to your email shortly'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'email_id',\n",
       "   'patterns': ['abc@gmail.com', 'abc@yahoo.com'],\n",
       "   'responses': ['The link has been sent. Please change your password!'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'manufacturing_problems',\n",
       "   'patterns': ['Please find me a manufacturer nearby'],\n",
       "   'responses': ['The nearest manufacturer is 20 miles away',\n",
       "    'The nearest manufacturer is 50 miles away'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'search_department',\n",
       "   'patterns': ['Please list the departments'],\n",
       "   'responses': ['The departments are: \\n-Engineering Research and Development, \\n-Manufacturing Systems Engineering, \\n-New Products Development, \\n-Manufacturing Department, \\n-Quality Department, \\n-Maintenance Department, \\n-Marketing Department, \\n-Human Resources Development, \\n-Personnel Department, \\n-Finance Department'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'key_customers',\n",
       "   'patterns': ['Our Target customers', 'Who are your target customers?'],\n",
       "   'responses': ['Our target customers are in the age range of 20-40'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'supplier_info',\n",
       "   'patterns': ['What information is shared with supplier?'],\n",
       "   'responses': ['Production Schedule, Delivery Schedule'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'highest_grossing',\n",
       "   'patterns': ['What is the highest grossing product?'],\n",
       "   'responses': ['iPhone X', 'Platform boots'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'connect_people',\n",
       "   'patterns': ['I want to meet the head of the HR/IT/Projects departments',\n",
       "    'I want to meet the head of HR.'],\n",
       "   'responses': ['I will just check if he or she is available.'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'solve_problems',\n",
       "   'patterns': ['Lack of product clarity',\n",
       "    'the specifications for the product are not clear to the customer. What can be done?'],\n",
       "   'responses': ['Please enter an order. Specifications will be sent to user!'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'predict_performance',\n",
       "   'patterns': ['how have we improved sales from last year?',\n",
       "    'what is the profit margin this year?'],\n",
       "   'responses': ['we have improved sales by increasing the customer base',\n",
       "    'profit earnings are at 15%'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'customer_satisfaction',\n",
       "   'patterns': ['how was the customer response',\n",
       "    'Is the customer happy?',\n",
       "    'what was the customer feedback?'],\n",
       "   'responses': ['Customer was happy and has given good rating'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'gadgets',\n",
       "   'patterns': ['What are the gadgets in stock?',\n",
       "    'which products are available?'],\n",
       "   'responses': ['hardisk, wireless bluetooth, laptop, gaming console'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'invalid',\n",
       "   'patterns': ['chat with me',\n",
       "    'I am confused',\n",
       "    \"I don't know what to work on\"],\n",
       "   'responses': ['Please ask a more specific question.'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'noans',\n",
       "   'patterns': ['why', 'how', 'when', 'I', 'you'],\n",
       "   'responses': [\"Can't understand your question\", 'Please elaborate!'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'turnover',\n",
       "   'patterns': ['what is the turnover at this company at present?'],\n",
       "   'responses': ['I do not have an answer to your question.'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'predict_delay',\n",
       "   'patterns': ['why is order 55555 delayed?'],\n",
       "   'responses': ['delay is due to manufacuring',\n",
       "    'Delay is due to unavailable components'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'name',\n",
       "   'patterns': ['what is your name?', 'what should I call you?'],\n",
       "   'responses': ['You can call me CSUBot', \"Hey! I'm CSUBot\"],\n",
       "   'context': ['']},\n",
       "  {'tag': 'about',\n",
       "   'patterns': ['how you doing?', 'how are you?'],\n",
       "   'responses': ['Thanks For asking! I am good. How can I help you?'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'configuration',\n",
       "   'patterns': ['How to configure my laptop?',\n",
       "    'software configuration of a laptop',\n",
       "    'steps to configure a laptop',\n",
       "    'How to configure my computer?',\n",
       "    'software configuration for a computer',\n",
       "    'steps to configure my computer',\n",
       "    'How to configure my desktop?',\n",
       "    'software configuration for a desktop',\n",
       "    'steps to configure a desktop'],\n",
       "   'responses': ['search tab->control panel->select specific application->download update->give permission'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'Weather',\n",
       "   'patterns': ['what is the weather today?',\n",
       "    'weather',\n",
       "    'Weather',\n",
       "    'What is the weather forecast in ',\n",
       "    'What is the weather forecast in France?',\n",
       "    'What is the weather forecast in Germany?',\n",
       "    'What is the weather forecast in England?',\n",
       "    'What is the weather forecast in the United States?'],\n",
       "   'responses': [\"The weather displays below using the country's language.\"],\n",
       "   'context': ['']},\n",
       "  {'tag': 'leave',\n",
       "   'patterns': ['Is Jane Doe on leave?',\n",
       "    'Is James Jones present today?',\n",
       "    'Is Jane Doe in the office?'],\n",
       "   'responses': ['Give me a moment! I will check', 'yes', 'no'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'hours',\n",
       "   'patterns': ['Opening hours for the cafeteria?',\n",
       "    'when does the cafeteria open',\n",
       "    'office restaurant opening time'],\n",
       "   'responses': ['It is open from Monday-Saturday from 9:00am to 5:00pm'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'domain',\n",
       "   'patterns': ['How to improve team members domain knowledge',\n",
       "    'improving domain knowledge for team members'],\n",
       "   'responses': ['set up meetings and workshop, \\ncreate a shared drive for holding information, \\nHold information sharing session'],\n",
       "   'context': ['']},\n",
       "  {'tag': 'Cars',\n",
       "   'patterns': ['How much is a 2022 honda odyssey?',\n",
       "    'How much is a 2022 mini convertible?'],\n",
       "   'responses': ['A 2022 honda odyssey costs between 32k and 49k',\n",
       "    'A 2022 mini convertible costs between 28k and 39k'],\n",
       "   'context': ''},\n",
       "  {'tag': 'dogs',\n",
       "   'patterns': ['Chihuahua', 'Italian Greyhound'],\n",
       "   'responses': ['They can live 10 to 15 years',\n",
       "    'They enjoy treats and walks in nature'],\n",
       "   'context': ''}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 Loading the Dataset: intents.json\n",
    "# source intents: https://github.com/dianastubbegit/ChatBot\n",
    "\n",
    "data_file = open(data_root + '/intents.json').read()\n",
    "data = json.loads(data_file)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GlfhvlVMGMgA",
    "outputId": "983f9dbf-234e-4435-dfda-f712e2a2ff9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "#4 Extracting data_X(features) and data_Y(Target)\n",
    "\n",
    "words = [] #For Bow model/ vocabulary for patterns\n",
    "classes = [] #For Bow  model/ vocabulary for tags\n",
    "data_X = [] #For storing each pattern\n",
    "data_y = [] #For storing tag corresponding to each pattern in data_X \n",
    "# Iterating over all the intents\n",
    "\n",
    "for intent in data[\"intents\"]:\n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        tokens = nltk.word_tokenize(pattern) # tokenize each pattern \n",
    "        words.extend(tokens) #and append tokens to words\n",
    "        data_X.append(pattern) #appending pattern to data_X\n",
    "        data_y.append(intent[\"tag\"]) ,# appending the associated tag to each pattern \n",
    "    \n",
    "    # adding the tag to the classes if it's not there already \n",
    "    if intent[\"tag\"] not in classes:\n",
    "        classes.append(intent[\"tag\"])\n",
    "\n",
    "# initializing lemmatizer to get stem of words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# lemmatize all the words in the vocab and convert them to lowercase\n",
    "# if the words don't appear in punctuation\n",
    "words = [lemmatizer.lemmatize(word.lower()) for word in words if word not in string.punctuation]\n",
    "# sorting the vocab and classes in alphabetical order and taking the # set to ensure no duplicates occur\n",
    "words = sorted(set(words))\n",
    "classes = sorted(set(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KxXzyJNNR17c"
   },
   "outputs": [],
   "source": [
    "# 5 Text to Numbers\n",
    "training = []\n",
    "out_empty = [0] * len(classes)\n",
    "# creating the bag of words model\n",
    "for idx, doc in enumerate(data_X):\n",
    "    bow = []\n",
    "    text = lemmatizer.lemmatize(doc.lower())\n",
    "    for word in words:\n",
    "        bow.append(1) if word in text else bow.append(0)\n",
    "    # mark the index of class that the current pattern is associated\n",
    "    # to\n",
    "    output_row = list(out_empty)\n",
    "    output_row[classes.index(data_y[idx])] = 1\n",
    "    # add the one hot encoded BoW and associated classes to training \n",
    "    training.append([bow, output_row])\n",
    "# shuffle the data and convert it to an array\n",
    "random.shuffle(training)\n",
    "training = np.array(training, dtype=object)\n",
    "# split the features and target labels\n",
    "train_X = np.array(list(training[:, 0]))\n",
    "train_Y = np.array(list(training[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_Q343LiR9w1",
    "outputId": "02304a76-5226-4e03-ad0a-bc47e5d58001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               22912     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 37)                2405      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,573\n",
      "Trainable params: 33,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "4/4 [==============================] - 1s 4ms/step - loss: 3.6077 - accuracy: 0.0377\n",
      "Epoch 2/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.4014 - accuracy: 0.1509\n",
      "Epoch 3/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3.1836 - accuracy: 0.2264\n",
      "Epoch 4/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.8445 - accuracy: 0.2453\n",
      "Epoch 5/150\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2.6013 - accuracy: 0.3396\n",
      "Epoch 6/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.3461 - accuracy: 0.4057\n",
      "Epoch 7/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2.1835 - accuracy: 0.4057\n",
      "Epoch 8/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.9544 - accuracy: 0.5377\n",
      "Epoch 9/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.8516 - accuracy: 0.4717\n",
      "Epoch 10/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.6495 - accuracy: 0.5472\n",
      "Epoch 11/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4059 - accuracy: 0.5943\n",
      "Epoch 12/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.5072 - accuracy: 0.5283\n",
      "Epoch 13/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1510 - accuracy: 0.6604\n",
      "Epoch 14/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9900 - accuracy: 0.6698\n",
      "Epoch 15/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9809 - accuracy: 0.6981\n",
      "Epoch 16/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9121 - accuracy: 0.7453\n",
      "Epoch 17/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7376 - accuracy: 0.7547\n",
      "Epoch 18/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7572 - accuracy: 0.7736\n",
      "Epoch 19/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7395 - accuracy: 0.7642\n",
      "Epoch 20/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7498 - accuracy: 0.7925\n",
      "Epoch 21/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5463 - accuracy: 0.8302\n",
      "Epoch 22/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.8208\n",
      "Epoch 23/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7082 - accuracy: 0.7830\n",
      "Epoch 24/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.8302\n",
      "Epoch 25/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6715 - accuracy: 0.7358\n",
      "Epoch 26/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5036 - accuracy: 0.8491\n",
      "Epoch 27/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5678 - accuracy: 0.8208\n",
      "Epoch 28/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.8491\n",
      "Epoch 29/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.8774\n",
      "Epoch 30/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.8396\n",
      "Epoch 31/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4950 - accuracy: 0.8396\n",
      "Epoch 32/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.8396\n",
      "Epoch 33/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3785 - accuracy: 0.8774\n",
      "Epoch 34/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.8585\n",
      "Epoch 35/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3880 - accuracy: 0.8868\n",
      "Epoch 36/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2686 - accuracy: 0.9245\n",
      "Epoch 37/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.8868\n",
      "Epoch 38/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.8302\n",
      "Epoch 39/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.8679\n",
      "Epoch 40/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2901 - accuracy: 0.9151\n",
      "Epoch 41/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3081 - accuracy: 0.9245\n",
      "Epoch 42/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3046 - accuracy: 0.9245\n",
      "Epoch 43/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8679\n",
      "Epoch 44/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.8302\n",
      "Epoch 45/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.8491\n",
      "Epoch 46/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.8774\n",
      "Epoch 47/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4978 - accuracy: 0.8585\n",
      "Epoch 48/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3569 - accuracy: 0.8774\n",
      "Epoch 49/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3238 - accuracy: 0.9245\n",
      "Epoch 50/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.8679\n",
      "Epoch 51/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3611 - accuracy: 0.8679\n",
      "Epoch 52/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3776 - accuracy: 0.8585\n",
      "Epoch 53/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3820 - accuracy: 0.8868\n",
      "Epoch 54/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3597 - accuracy: 0.9151\n",
      "Epoch 55/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3200 - accuracy: 0.8774\n",
      "Epoch 56/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3346 - accuracy: 0.8679\n",
      "Epoch 57/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2805 - accuracy: 0.8962\n",
      "Epoch 58/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.9151\n",
      "Epoch 59/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.9151\n",
      "Epoch 60/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3445 - accuracy: 0.8868\n",
      "Epoch 61/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3627 - accuracy: 0.9245\n",
      "Epoch 62/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2645 - accuracy: 0.9340\n",
      "Epoch 63/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2678 - accuracy: 0.9340\n",
      "Epoch 64/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3096 - accuracy: 0.8774\n",
      "Epoch 65/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1986 - accuracy: 0.9245\n",
      "Epoch 66/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.8396\n",
      "Epoch 67/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2708 - accuracy: 0.8962\n",
      "Epoch 68/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1127 - accuracy: 0.9811\n",
      "Epoch 69/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3759 - accuracy: 0.8774\n",
      "Epoch 70/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2552 - accuracy: 0.9245\n",
      "Epoch 71/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1944 - accuracy: 0.9340\n",
      "Epoch 72/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1734 - accuracy: 0.9340\n",
      "Epoch 73/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2714 - accuracy: 0.9057\n",
      "Epoch 74/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3824 - accuracy: 0.8679\n",
      "Epoch 75/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2372 - accuracy: 0.9340\n",
      "Epoch 76/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3277 - accuracy: 0.9057\n",
      "Epoch 77/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1640 - accuracy: 0.9434\n",
      "Epoch 78/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.8679\n",
      "Epoch 79/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2450 - accuracy: 0.9340\n",
      "Epoch 80/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2238 - accuracy: 0.9057\n",
      "Epoch 81/150\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1955 - accuracy: 0.9340\n",
      "Epoch 82/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1957 - accuracy: 0.9528\n",
      "Epoch 83/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4132 - accuracy: 0.8585\n",
      "Epoch 84/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2162 - accuracy: 0.9245\n",
      "Epoch 85/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1925 - accuracy: 0.9340\n",
      "Epoch 86/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2164 - accuracy: 0.9245\n",
      "Epoch 87/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2944 - accuracy: 0.9151\n",
      "Epoch 88/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2819 - accuracy: 0.9057\n",
      "Epoch 89/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2893 - accuracy: 0.8774\n",
      "Epoch 90/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3044 - accuracy: 0.9151\n",
      "Epoch 91/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2713 - accuracy: 0.9245\n",
      "Epoch 92/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3481 - accuracy: 0.8962\n",
      "Epoch 93/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3196 - accuracy: 0.8962\n",
      "Epoch 94/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8679\n",
      "Epoch 95/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2540 - accuracy: 0.9057\n",
      "Epoch 96/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2425 - accuracy: 0.9057\n",
      "Epoch 97/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1905 - accuracy: 0.9434\n",
      "Epoch 98/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1841 - accuracy: 0.9245\n",
      "Epoch 99/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1534 - accuracy: 0.9434\n",
      "Epoch 100/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1764 - accuracy: 0.9434\n",
      "Epoch 101/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3239 - accuracy: 0.8774\n",
      "Epoch 102/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2010 - accuracy: 0.9340\n",
      "Epoch 103/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.8774\n",
      "Epoch 104/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2886 - accuracy: 0.9057\n",
      "Epoch 105/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1958 - accuracy: 0.9245\n",
      "Epoch 106/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8868\n",
      "Epoch 107/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3610 - accuracy: 0.9151\n",
      "Epoch 108/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3467 - accuracy: 0.9434\n",
      "Epoch 109/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1284 - accuracy: 0.9811\n",
      "Epoch 110/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2926 - accuracy: 0.9151\n",
      "Epoch 111/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2594 - accuracy: 0.8962\n",
      "Epoch 112/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2565 - accuracy: 0.9245\n",
      "Epoch 113/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1785 - accuracy: 0.9340\n",
      "Epoch 114/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2033 - accuracy: 0.9623\n",
      "Epoch 115/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1394 - accuracy: 0.9623\n",
      "Epoch 116/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2536 - accuracy: 0.9340\n",
      "Epoch 117/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2648 - accuracy: 0.9340\n",
      "Epoch 118/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2883 - accuracy: 0.9151\n",
      "Epoch 119/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2720 - accuracy: 0.9057\n",
      "Epoch 120/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2588 - accuracy: 0.9340\n",
      "Epoch 121/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2923 - accuracy: 0.9245\n",
      "Epoch 122/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.8679\n",
      "Epoch 123/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2726 - accuracy: 0.9151\n",
      "Epoch 124/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1961 - accuracy: 0.9245\n",
      "Epoch 125/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2641 - accuracy: 0.9057\n",
      "Epoch 126/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.8491\n",
      "Epoch 127/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3751 - accuracy: 0.8774\n",
      "Epoch 128/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3556 - accuracy: 0.9057\n",
      "Epoch 129/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.9434\n",
      "Epoch 130/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2667 - accuracy: 0.9057\n",
      "Epoch 131/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8868\n",
      "Epoch 132/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2848 - accuracy: 0.9151\n",
      "Epoch 133/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3657 - accuracy: 0.8868\n",
      "Epoch 134/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2227 - accuracy: 0.9151\n",
      "Epoch 135/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2655 - accuracy: 0.8962\n",
      "Epoch 136/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1711 - accuracy: 0.9151\n",
      "Epoch 137/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2429 - accuracy: 0.9434\n",
      "Epoch 138/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2912 - accuracy: 0.9151\n",
      "Epoch 139/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2578 - accuracy: 0.9151\n",
      "Epoch 140/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3085 - accuracy: 0.9245\n",
      "Epoch 141/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3548 - accuracy: 0.8679\n",
      "Epoch 142/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3170 - accuracy: 0.9340\n",
      "Epoch 143/150\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2107 - accuracy: 0.9340\n",
      "Epoch 144/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2500 - accuracy: 0.9623\n",
      "Epoch 145/150\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2750 - accuracy: 0.9057\n",
      "Epoch 146/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1358 - accuracy: 0.9434\n",
      "Epoch 147/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2832 - accuracy: 0.9245\n",
      "Epoch 148/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2855 - accuracy: 0.8962\n",
      "Epoch 149/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2936 - accuracy: 0.9151\n",
      "Epoch 150/150\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2158 - accuracy: 0.9245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0afd1f56d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6 The Neural Network Model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(len(train_X[0]),), activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_Y[0]), activation = \"softmax\"))\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=[\"accuracy\"])\n",
    "print(model.summary())\n",
    "model.fit(x=train_X, y=train_Y, epochs=150, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bjWR6_B7SJ-_"
   },
   "outputs": [],
   "source": [
    "#7 Preprocessing the Input\n",
    "\n",
    "def clean_text(text): \n",
    "  tokens = nltk.word_tokenize(text)\n",
    "  tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "  return tokens\n",
    "\n",
    "def bag_of_words(text, vocab): \n",
    "  tokens = clean_text(text)\n",
    "  bow = [0] * len(vocab)\n",
    "  for w in tokens: \n",
    "    for idx, word in enumerate(vocab):\n",
    "      if word == w: \n",
    "        bow[idx] = 1\n",
    "  return np.array(bow)\n",
    "\n",
    "def pred_class(text, vocab, labels): \n",
    "  bow = bag_of_words(text, vocab)\n",
    "  result = model.predict(np.array([bow]))[0] #Extracting probabilities\n",
    "  thresh = 0.5\n",
    "  y_pred = [[indx, res] for indx, res in enumerate(result) if res > thresh]\n",
    "  y_pred.sort(key=lambda x: x[1], reverse=True) #Sorting by values of probability in decreasing order\n",
    "  return_list = []\n",
    "  for r in y_pred:\n",
    "    return_list.append(labels[r[0]]) #Contains labels(tags) for highest probability \n",
    "  return return_list\n",
    "\n",
    "def get_response(intents_list, intents_json): \n",
    "  if len(intents_list) == 0:\n",
    "    result = \"Sorry! I don't understand.\"\n",
    "  else:\n",
    "    tag = intents_list[0]\n",
    "    list_of_intents = intents_json[\"intents\"]\n",
    "    for i in list_of_intents: \n",
    "      if i[\"tag\"] == tag:\n",
    "        result = random.choice(i[\"responses\"])\n",
    "        break\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "vQLRSslMSQ9s",
    "outputId": "4054a9e6-0335-40d5-e7c9-444bffe02e14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 0 if you don't want to chat with our ChatBot.\n",
      "hey\n",
      "Hi there, how can I help?\n",
      "weather in Gothenburg\n",
      "The weather displays below using the country's language.\n",
      "swedish\n",
      "Can't understand your question\n",
      "weather in paris\n",
      "The weather displays below using the country's language.\n",
      "Weather\n",
      "Can't understand your question\n",
      "leave\n",
      "Can't understand your question\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-40be2bf8046a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Press 0 if you don't want to chat with our ChatBot.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         )\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Interacting with the chatbot\n",
    "print(\"Press 0 if you don't want to chat with our ChatBot.\")\n",
    "while True:\n",
    "    message = input(\"\")\n",
    "    if message == \"0\":\n",
    "      break\n",
    "    intents = pred_class(message, words, classes)\n",
    "    result = get_response(intents, data)\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
